{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# openNanoBanana -- Free Colab Edition\n",
        "\n",
        "The full openNanoBanana pipeline running on a free Google Colab T4 GPU.\n",
        "\n",
        "**Pipeline:**\n",
        "1. Gemini 3 Flash extracts the real-world subject from your prompt\n",
        "2. Serper.dev searches Google Images for reference photos\n",
        "3. Gemini 3 Flash verifies the images match the subject\n",
        "4. FLUX.2-klein-4B generates the final image locally on your T4 GPU\n",
        "\n",
        "**Before you start:**\n",
        "- Runtime > Change runtime type > **T4 GPU**\n",
        "- Add `GEMINI_API_KEY` and `SERPER_API_KEY` to Colab Secrets (key icon in left sidebar)\n",
        "- Optionally add `HF_TOKEN` for faster model downloads\n",
        "\n",
        "**Get API keys:**\n",
        "- Gemini: [aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey) (free)\n",
        "- Serper: [serper.dev](https://serper.dev) (2,500 free queries/month, no credit card)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 1: Check GPU + Install Dependencies\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"\\nPyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "    print(f\"Compute capability: {torch.cuda.get_device_capability()}\")\n",
        "\n",
        "print(\"\\nInstalling dependencies...\")\n",
        "!pip install -q git+https://github.com/huggingface/diffusers.git\n",
        "!pip install -q transformers accelerate safetensors\n",
        "!pip install -q gradio Pillow requests\n",
        "print(\"\\nDone!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 2: Configure API Keys\n",
        "from google.colab import userdata\n",
        "\n",
        "# Gemini API key (REQUIRED)\n",
        "try:\n",
        "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "    print(\"GEMINI_API_KEY found\")\n",
        "except Exception:\n",
        "    GEMINI_API_KEY = None\n",
        "    print(\"WARNING: GEMINI_API_KEY not found!\")\n",
        "    print(\"  Get one at: https://aistudio.google.com/app/apikey\")\n",
        "    print(\"  Then add it to Colab Secrets (key icon in left sidebar)\")\n",
        "\n",
        "# Serper API key (REQUIRED)\n",
        "try:\n",
        "    SERPER_API_KEY = userdata.get('SERPER_API_KEY')\n",
        "    print(\"SERPER_API_KEY found\")\n",
        "except Exception:\n",
        "    SERPER_API_KEY = None\n",
        "    print(\"WARNING: SERPER_API_KEY not found!\")\n",
        "    print(\"  Get one at: https://serper.dev (free, no credit card)\")\n",
        "    print(\"  Then add it to Colab Secrets\")\n",
        "\n",
        "# HuggingFace token (optional, for faster model downloads)\n",
        "try:\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    from huggingface_hub import login\n",
        "    login(token=HF_TOKEN, add_to_git_credential=False)\n",
        "    print(\"Logged in to HuggingFace\")\n",
        "except Exception:\n",
        "    print(\"No HF_TOKEN -- downloading anonymously (may be slower)\")\n",
        "\n",
        "GEMINI_MODEL = \"gemini-3-flash-preview\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 3: Load FLUX.2-klein-4B\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "# T4 has excellent FP16 tensor cores (65 TFLOPS)\n",
        "# T4 does NOT have native BF16 cores -- BF16 falls back to FP32 emulation\n",
        "dtype = torch.float16\n",
        "\n",
        "print(\"Loading FLUX.2-klein-4B (this takes 2-4 minutes on first run)...\")\n",
        "print(\"The model will be cached for subsequent runs.\\n\")\n",
        "\n",
        "from diffusers import Flux2KleinPipeline\n",
        "\n",
        "pipe = Flux2KleinPipeline.from_pretrained(\n",
        "    \"black-forest-labs/FLUX.2-klein-4B\",\n",
        "    torch_dtype=dtype,\n",
        ")\n",
        "\n",
        "# CPU offloading: only the active submodule is on GPU at a time\n",
        "# Peak GPU usage: ~4 GB instead of ~8 GB\n",
        "pipe.enable_model_cpu_offload()\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(f\"Model loaded!\")\n",
        "print(f\"GPU memory allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "print(f\"GPU memory reserved:  {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 4: Pipeline Functions\n",
        "# Python port of the openNanoBanana TypeScript pipeline\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import base64\n",
        "import time\n",
        "import re\n",
        "import torch\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/models\"\n",
        "SERPER_URL = \"https://google.serper.dev/images\"\n",
        "\n",
        "RESOLUTION_MAP = {\n",
        "    \"1k\": (512, 512),\n",
        "    \"2k\": (768, 768),\n",
        "}\n",
        "\n",
        "EXTRACT_PROMPT = \"\"\"You are a search query extractor. Given an image generation prompt, extract TWO things:\n",
        "\n",
        "1. **searchQuery**: The real-world subject to search for as a reference image. Remove artistic style descriptors, effects, transformations, or hypothetical modifiers (e.g. \"as a baby\", \"in cyberpunk style\", \"watercolor painting\").\n",
        "2. **subjectType**: A SHORT, generic visual description of what the subject IS -- the kind of thing a person could identify by looking at a photo (e.g. \"a person\", \"a bridge\", \"a building\", \"a cat\", \"a street crossing\"). Do NOT use the specific name. This is used to verify search results visually.\n",
        "\n",
        "Return ONLY valid JSON, no markdown fences, no explanation.\n",
        "\n",
        "Examples:\n",
        "- \"hkust entrance piazza in cyberpunk future\" -> {\"searchQuery\":\"hkust entrance piazza\",\"subjectType\":\"an outdoor plaza at a university\"}\n",
        "- \"golden gate bridge at sunset watercolor painting\" -> {\"searchQuery\":\"golden gate bridge\",\"subjectType\":\"a suspension bridge\"}\n",
        "- \"dr ct abraham as a baby\" -> {\"searchQuery\":\"dr ct abraham\",\"subjectType\":\"a person\"}\n",
        "- \"my cat wearing a top hat in van gogh style\" -> {\"searchQuery\":\"cat wearing top hat\",\"subjectType\":\"a cat\"}\n",
        "- \"tokyo shibuya crossing in anime style\" -> {\"searchQuery\":\"tokyo shibuya crossing\",\"subjectType\":\"a busy street crossing\"}\n",
        "- \"labrador puppy in a spacesuit\" -> {\"searchQuery\":\"labrador puppy\",\"subjectType\":\"a dog\"}\"\"\"\n",
        "\n",
        "\n",
        "# ===== Gemini Client =====\n",
        "\n",
        "def call_gemini(api_key, model, contents):\n",
        "    \"\"\"Call Gemini API and return the text response.\"\"\"\n",
        "    url = f\"{GEMINI_BASE_URL}/{model}:generateContent\"\n",
        "    res = requests.post(\n",
        "        url,\n",
        "        headers={\"x-goog-api-key\": api_key, \"Content-Type\": \"application/json\"},\n",
        "        json={\"contents\": contents},\n",
        "        timeout=30,\n",
        "    )\n",
        "    if res.status_code == 429:\n",
        "        raise Exception(\"Gemini rate limit hit. Wait a moment and try again.\")\n",
        "    if res.status_code in (401, 403):\n",
        "        raise Exception(\"Invalid Gemini API key.\")\n",
        "    if not res.ok:\n",
        "        raise Exception(f\"Gemini API error ({res.status_code}): {res.text[:200]}\")\n",
        "\n",
        "    data = res.json()\n",
        "    candidate = (data.get(\"candidates\") or [None])[0]\n",
        "\n",
        "    if not candidate:\n",
        "        block = data.get(\"promptFeedback\", {}).get(\"blockReason\")\n",
        "        if block:\n",
        "            raise Exception(f\"Content blocked by Gemini safety filters: {block}\")\n",
        "        raise Exception(\"Gemini returned no candidates.\")\n",
        "\n",
        "    if candidate.get(\"finishReason\") == \"SAFETY\":\n",
        "        raise Exception(\"Content blocked by Gemini safety filters.\")\n",
        "\n",
        "    text = (candidate.get(\"content\", {}).get(\"parts\") or [{}])[0].get(\"text\")\n",
        "    if not isinstance(text, str):\n",
        "        raise Exception(\"Gemini returned no text in response.\")\n",
        "    return text\n",
        "\n",
        "\n",
        "# ===== Step 1: Extract Search Query =====\n",
        "\n",
        "def extract_search_query(api_key, model, user_prompt):\n",
        "    \"\"\"Extract search query and subject type from user prompt. Returns (query, subject_type).\"\"\"\n",
        "    text = call_gemini(api_key, model, [\n",
        "        {\"parts\": [{\"text\": EXTRACT_PROMPT}, {\"text\": f'User prompt: \"{user_prompt}\"'}]}\n",
        "    ])\n",
        "    cleaned = re.sub(r\"^```json\\s*|```\\s*$\", \"\", text.strip()).strip()\n",
        "    try:\n",
        "        parsed = json.loads(cleaned)\n",
        "    except json.JSONDecodeError:\n",
        "        raise Exception(f\"Could not parse extraction result: {cleaned[:200]}\")\n",
        "\n",
        "    query = (parsed.get(\"searchQuery\") or \"\").strip().strip('\"\\'')\n",
        "    subject_type = (parsed.get(\"subjectType\") or \"a subject\").strip()\n",
        "\n",
        "    if not query or len(query) < 2:\n",
        "        raise Exception(\"Could not extract a search query from the prompt.\")\n",
        "    return query, subject_type\n",
        "\n",
        "\n",
        "# ===== Step 2: Search Images =====\n",
        "\n",
        "def search_images(api_key, query, num=5):\n",
        "    \"\"\"Search Google Images via Serper. Returns list of {title, imageUrl, link}.\"\"\"\n",
        "    res = requests.post(\n",
        "        SERPER_URL,\n",
        "        headers={\"X-API-KEY\": api_key, \"Content-Type\": \"application/json\"},\n",
        "        json={\"q\": query, \"num\": num},\n",
        "        timeout=15,\n",
        "    )\n",
        "    if res.status_code == 429:\n",
        "        raise Exception(\"Serper rate limit hit.\")\n",
        "    if res.status_code in (401, 403):\n",
        "        raise Exception(\"Invalid Serper API key.\")\n",
        "    if not res.ok:\n",
        "        raise Exception(f\"Serper API error ({res.status_code}): {res.text[:200]}\")\n",
        "\n",
        "    data = res.json()\n",
        "    images = [\n",
        "        {\"title\": img.get(\"title\", \"\"), \"imageUrl\": img.get(\"imageUrl\", \"\"), \"link\": img.get(\"link\", \"\")}\n",
        "        for img in data.get(\"images\", [])\n",
        "    ]\n",
        "    if not images:\n",
        "        raise Exception(f'No images found for \"{query}\". Try a more specific prompt.')\n",
        "    return images\n",
        "\n",
        "\n",
        "# ===== Image Download =====\n",
        "\n",
        "MIME_MAP = {\".jpg\": \"image/jpeg\", \".jpeg\": \"image/jpeg\", \".png\": \"image/png\", \".webp\": \"image/webp\", \".gif\": \"image/gif\"}\n",
        "\n",
        "def infer_mime(url, content_type=None):\n",
        "    if content_type and content_type.startswith(\"image/\"):\n",
        "        return content_type.split(\";\")[0].strip()\n",
        "    ext_match = re.search(r'\\.\\w+$', url.split(\"?\")[0])\n",
        "    if ext_match:\n",
        "        return MIME_MAP.get(ext_match.group(0).lower(), \"image/jpeg\")\n",
        "    return \"image/jpeg\"\n",
        "\n",
        "def fetch_image_as_base64(url, timeout=8):\n",
        "    \"\"\"Download image and return (base64_str, mime_type) or None.\"\"\"\n",
        "    try:\n",
        "        res = requests.get(url, timeout=timeout, headers={\"User-Agent\": \"openNanoBanana/1.0\"})\n",
        "        if not res.ok:\n",
        "            return None\n",
        "        ct = res.headers.get(\"Content-Type\", \"\")\n",
        "        if not ct.startswith(\"image/\"):\n",
        "            return None\n",
        "        if len(res.content) < 100:\n",
        "            return None\n",
        "        b64 = base64.b64encode(res.content).decode(\"utf-8\")\n",
        "        mime = infer_mime(url, ct)\n",
        "        return b64, mime\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def download_pil_image(url, timeout=10):\n",
        "    \"\"\"Download image and return PIL Image or None.\"\"\"\n",
        "    try:\n",
        "        res = requests.get(url, timeout=timeout, headers={\"User-Agent\": \"openNanoBanana/1.0\"})\n",
        "        res.raise_for_status()\n",
        "        return Image.open(BytesIO(res.content)).convert(\"RGB\")\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "# ===== Step 3: Verify Images =====\n",
        "\n",
        "def verify_images(api_key, model, subject_type, image_results):\n",
        "    \"\"\"Check each image with Gemini. Returns (imageUrl, base64, mime) of first match, or None.\"\"\"\n",
        "    for i, img in enumerate(image_results):\n",
        "        result = fetch_image_as_base64(img[\"imageUrl\"])\n",
        "        if result is None:\n",
        "            continue\n",
        "        b64, mime = result\n",
        "        try:\n",
        "            answer = call_gemini(api_key, model, [{\n",
        "                \"parts\": [\n",
        "                    {\"inline_data\": {\"mime_type\": mime, \"data\": b64}},\n",
        "                    {\"text\": f'Does this image clearly contain {subject_type}? Answer with ONLY \"yes\" or \"no\".'},\n",
        "                ]\n",
        "            }])\n",
        "            if answer.strip().lower().startswith(\"yes\"):\n",
        "                return {\"imageUrl\": img[\"imageUrl\"], \"base64\": b64, \"mimeType\": mime, \"index\": i}\n",
        "        except Exception:\n",
        "            continue\n",
        "    return None\n",
        "\n",
        "\n",
        "# ===== Step 4: Generate Image Locally =====\n",
        "\n",
        "def generate_image(flux_pipe, prompt, reference_image_url, resolution=\"1k\"):\n",
        "    \"\"\"Generate image using local FLUX.2 pipeline. Returns PIL Image.\"\"\"\n",
        "    h, w = RESOLUTION_MAP.get(resolution, (512, 512))\n",
        "\n",
        "    ref_img = download_pil_image(reference_image_url)\n",
        "    if ref_img is None:\n",
        "        raise Exception(\"Failed to download reference image for generation.\")\n",
        "    ref_img = ref_img.resize((w, h))\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        result = flux_pipe(\n",
        "            prompt=prompt,\n",
        "            image=[ref_img],\n",
        "            height=h,\n",
        "            width=w,\n",
        "            guidance_scale=4.0,\n",
        "            num_inference_steps=4,\n",
        "            generator=torch.Generator(device=\"cpu\").manual_seed(int(time.time()) % 2**32),\n",
        "        )\n",
        "    torch.cuda.empty_cache()\n",
        "    return result.images[0]\n",
        "\n",
        "\n",
        "# ===== Full Pipeline Orchestrator =====\n",
        "\n",
        "def run_pipeline(prompt, gemini_key, serper_key, flux_pipe, model=GEMINI_MODEL, resolution=\"1k\"):\n",
        "    \"\"\"\n",
        "    Run the full openNanoBanana pipeline.\n",
        "    Returns (final_image, gallery_images, verified_index, log_text).\n",
        "    \"\"\"\n",
        "    log = []\n",
        "\n",
        "    # Step 1: Extract search query\n",
        "    log.append(\"[1/4] Extracting search query...\")\n",
        "    query, subject_type = extract_search_query(gemini_key, model, prompt)\n",
        "    log.append(f'  Search query: \"{query}\"')\n",
        "    log.append(f'  Subject type: \"{subject_type}\"')\n",
        "\n",
        "    # Step 2: Search images\n",
        "    log.append(f'\\n[2/4] Searching Google Images for \"{query}\"...')\n",
        "    results = search_images(serper_key, query, num=5)\n",
        "    log.append(f\"  Found {len(results)} candidate images\")\n",
        "\n",
        "    # Download thumbnails for gallery\n",
        "    gallery_images = []\n",
        "    for img in results:\n",
        "        pil = download_pil_image(img[\"imageUrl\"])\n",
        "        if pil:\n",
        "            gallery_images.append((pil, img[\"title\"][:60]))\n",
        "        else:\n",
        "            gallery_images.append(None)\n",
        "\n",
        "    # Step 3: Verify images\n",
        "    log.append(\"\\n[3/4] Verifying images match the subject...\")\n",
        "    verified = verify_images(gemini_key, model, subject_type, results)\n",
        "    if not verified:\n",
        "        raise Exception(\"None of the found images match the subject. Try rephrasing your prompt.\")\n",
        "    log.append(f'  Verified image #{verified[\"index\"] + 1}: {results[verified[\"index\"]][\"title\"][:60]}')\n",
        "\n",
        "    # Step 4: Generate\n",
        "    log.append(\"\\n[4/4] Generating image with FLUX.2-klein-4B (this may take 10-30s)...\")\n",
        "    final_image = generate_image(flux_pipe, prompt, verified[\"imageUrl\"], resolution)\n",
        "    log.append(\"  Done!\")\n",
        "\n",
        "    # Filter out None entries from gallery\n",
        "    gallery_clean = [g for g in gallery_images if g is not None]\n",
        "\n",
        "    return final_image, gallery_clean, verified[\"index\"], \"\\n\".join(log)\n",
        "\n",
        "\n",
        "print(\"Pipeline functions loaded.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 5: Gradio UI\n",
        "import gradio as gr\n",
        "\n",
        "def generate_handler(prompt, resolution):\n",
        "    \"\"\"Gradio handler for the generate button.\"\"\"\n",
        "    if not GEMINI_API_KEY:\n",
        "        raise gr.Error(\"GEMINI_API_KEY not set. Add it to Colab Secrets.\")\n",
        "    if not SERPER_API_KEY:\n",
        "        raise gr.Error(\"SERPER_API_KEY not set. Add it to Colab Secrets.\")\n",
        "    if not prompt or len(prompt.strip()) < 3:\n",
        "        raise gr.Error(\"Please enter a prompt (at least 3 characters).\")\n",
        "\n",
        "    try:\n",
        "        final_image, gallery, verified_idx, log = run_pipeline(\n",
        "            prompt=prompt.strip(),\n",
        "            gemini_key=GEMINI_API_KEY,\n",
        "            serper_key=SERPER_API_KEY,\n",
        "            flux_pipe=pipe,\n",
        "            resolution=resolution,\n",
        "        )\n",
        "        return final_image, gallery, log\n",
        "    except Exception as e:\n",
        "        raise gr.Error(str(e))\n",
        "\n",
        "\n",
        "with gr.Blocks(title=\"openNanoBanana\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# openNanoBanana\")\n",
        "    gr.Markdown(\"Real-time grounded image generation. Type a prompt with a real-world subject -- the pipeline searches for reference images, verifies them, and generates a new image grounded in reality.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3):\n",
        "            prompt_input = gr.Textbox(\n",
        "                label=\"Prompt\",\n",
        "                placeholder=\"andrej karpathy in a gta v poster\",\n",
        "                lines=2,\n",
        "            )\n",
        "        with gr.Column(scale=1):\n",
        "            resolution_input = gr.Dropdown(\n",
        "                choices=[\"1k\", \"2k\"],\n",
        "                value=\"1k\",\n",
        "                label=\"Resolution\",\n",
        "            )\n",
        "            generate_btn = gr.Button(\"Generate\", variant=\"primary\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            output_image = gr.Image(label=\"Generated Image\", type=\"pil\")\n",
        "        with gr.Column():\n",
        "            gallery_output = gr.Gallery(label=\"Reference Images Found\", columns=3, height=300)\n",
        "            log_output = gr.Textbox(label=\"Pipeline Log\", lines=12, interactive=False)\n",
        "\n",
        "    generate_btn.click(\n",
        "        fn=generate_handler,\n",
        "        inputs=[prompt_input, resolution_input],\n",
        "        outputs=[output_image, gallery_output, log_output],\n",
        "    )\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [\"hkust entrance piazza in cyberpunk future\", \"1k\"],\n",
        "            [\"andrej karpathy in a gta v poster\", \"1k\"],\n",
        "            [\"golden gate bridge at sunset watercolor painting\", \"1k\"],\n",
        "            [\"tokyo shibuya crossing in anime style\", \"1k\"],\n",
        "        ],\n",
        "        inputs=[prompt_input, resolution_input],\n",
        "    )\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}